{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "953332b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\chaimae\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\chaimae\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Basic Libraries\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feb070ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>و الله حرام و الله موتوه لشعب الاردني من وين ب...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>البنزين يجي من السعوديه بأقل الاسعار و الحكومه...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>الله يوخذكم</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>شو هاد البرنامج معقول عرضوه على القنوات!!!!!!...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>للأسف البعض يعتقد ان المفاعل النووي سيحل مشاكل...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label\n",
       "0  و الله حرام و الله موتوه لشعب الاردني من وين ب...      0\n",
       "1  البنزين يجي من السعوديه بأقل الاسعار و الحكومه...      0\n",
       "2                                        الله يوخذكم      0\n",
       "3   شو هاد البرنامج معقول عرضوه على القنوات!!!!!!...      0\n",
       "4  للأسف البعض يعتقد ان المفاعل النووي سيحل مشاكل...      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Data\n",
    "# training data\n",
    "train = pd.read_csv(\"all.csv\", sep=\";\")\n",
    "train.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddd05698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Positive tweets\n",
    "sum(train[\"label\"] == 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51211e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "984"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Negative tweets\n",
    "sum(train[\"label\"] == 0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5619299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there are any missing values\n",
    "train.isnull().sum()\n",
    "train.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ce3621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary libraries\n",
    "import preprocessor as p\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import ISRIStemmer\n",
    "\n",
    "# custum function to clean the dataset \n",
    "\n",
    "def clean_tweets(data):\n",
    " tempArr = []\n",
    " for text in data:\n",
    "    # Suppression des caractères indésirables\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text) #Removing numeric values\n",
    "    # Expression régulière pour détecter les mots en latin\n",
    "    latin_pattern = re.compile(r'[a-zA-Z]+')\n",
    "\n",
    "    # Supprimer les mots en latin\n",
    "    text = re.sub(latin_pattern, '', text)\n",
    "    # Word normalization\n",
    "    stemmer = ISRIStemmer()\n",
    "    normalized_text = ' '.join(stemmer.stem(word) for word in word_tokenize(text))\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('arabic'))\n",
    "    filtered_text = ' '.join(word for word in word_tokenize(normalized_text) if word.lower() not in stop_words)\n",
    "    tempArr.append( filtered_text)\n",
    " return tempArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d53cdcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>و الله حرام و الله موتوه لشعب الاردني من وين ب...</td>\n",
       "      <td>0</td>\n",
       "      <td>الل حرم الل وته شعب ارد وين بدن نجب لكو وين ال...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>البنزين يجي من السعوديه بأقل الاسعار و الحكومه...</td>\n",
       "      <td>0</td>\n",
       "      <td>بنز يجي سعد سعر حكم دبل سعر</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>الله يوخذكم</td>\n",
       "      <td>0</td>\n",
       "      <td>الل وخذ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>شو هاد البرنامج معقول عرضوه على القنوات!!!!!!...</td>\n",
       "      <td>0</td>\n",
       "      <td>شو هاد رنمج عقل عرضو قنو</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>للأسف البعض يعتقد ان المفاعل النووي سيحل مشاكل...</td>\n",
       "      <td>0</td>\n",
       "      <td>اسف عقد ان فعل نوي يحل شكل اقتصادية ارد ملك ال...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>المفاعل النووي سيحتاج لشريك استراتيجي يمتلكه ا...</td>\n",
       "      <td>0</td>\n",
       "      <td>فعل نوي حاج لشر استراتيجي ملك او جزء كبر دفع ح...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>المفاعل النووي سيحتاج لشريك استراتيجي يمتلكه ا...</td>\n",
       "      <td>0</td>\n",
       "      <td>فعل نوي حاج لشر استراتيجي ملك او جزء كبر دفع ح...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>الطاقة الشمسية هي البديل و ليست النووية</td>\n",
       "      <td>0</td>\n",
       "      <td>طقة شمس بدل نوي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>للأسف البعض يعتقد ان المفاعل النووي سيحل مشاكل...</td>\n",
       "      <td>0</td>\n",
       "      <td>اسف عقد ان فعل نوي يحل شكل اقتصادية ارد ملك ال...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>للي مفكرين المفاعل راح يطورهم - المفاعل راح يد...</td>\n",
       "      <td>0</td>\n",
       "      <td>للي فكر فعل يطر فعل دمر ارد نطق الل حول لأن فس...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label  \\\n",
       "0  و الله حرام و الله موتوه لشعب الاردني من وين ب...      0   \n",
       "1  البنزين يجي من السعوديه بأقل الاسعار و الحكومه...      0   \n",
       "2                                        الله يوخذكم      0   \n",
       "3   شو هاد البرنامج معقول عرضوه على القنوات!!!!!!...      0   \n",
       "4  للأسف البعض يعتقد ان المفاعل النووي سيحل مشاكل...      0   \n",
       "5  المفاعل النووي سيحتاج لشريك استراتيجي يمتلكه ا...      0   \n",
       "6  المفاعل النووي سيحتاج لشريك استراتيجي يمتلكه ا...      0   \n",
       "7            الطاقة الشمسية هي البديل و ليست النووية      0   \n",
       "8  للأسف البعض يعتقد ان المفاعل النووي سيحل مشاكل...      0   \n",
       "9  للي مفكرين المفاعل راح يطورهم - المفاعل راح يد...      0   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0  الل حرم الل وته شعب ارد وين بدن نجب لكو وين ال...  \n",
       "1                        بنز يجي سعد سعر حكم دبل سعر  \n",
       "2                                            الل وخذ  \n",
       "3                           شو هاد رنمج عقل عرضو قنو  \n",
       "4  اسف عقد ان فعل نوي يحل شكل اقتصادية ارد ملك ال...  \n",
       "5  فعل نوي حاج لشر استراتيجي ملك او جزء كبر دفع ح...  \n",
       "6  فعل نوي حاج لشر استراتيجي ملك او جزء كبر دفع ح...  \n",
       "7                                    طقة شمس بدل نوي  \n",
       "8  اسف عقد ان فعل نوي يحل شكل اقتصادية ارد ملك ال...  \n",
       "9  للي فكر فعل يطر فعل دمر ارد نطق الل حول لأن فس...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean training data\n",
    "train_tweet = clean_tweets(train[\"tweet\"])\n",
    "train_tweet = pd.DataFrame(train_tweet)\n",
    "# append cleaned tweets to the training data\n",
    "train[\"clean_tweet\"] = train_tweet\n",
    "\n",
    "# compare the cleaned and uncleaned tweets\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9ef31d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# extract the labels from the train data\n",
    "y = train.label.values\n",
    "\n",
    "# use 70% for the training and 30% for the test\n",
    "x_train, x_test, y_train, y_test = train_test_split(train.clean_tweet.values, y, \n",
    "                                                    stratify=y, \n",
    "                                                    random_state=1, \n",
    "                                                    test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3b90322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\chaimae\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# vectorize tweets for model building\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Import de la liste de mots vides en arabe\n",
    "stop_words = stopwords.words('arabic')\n",
    "vectorizer = CountVectorizer(stop_words=stop_words)\n",
    "\n",
    "\n",
    "# learn a vocabulary dictionary of all tokens in the raw documents\n",
    "vectorizer.fit(list(x_train) + list(x_test))\n",
    "\n",
    "# transform documents to document-term matrix\n",
    "x_train_vec = vectorizer.transform(x_train)\n",
    "x_test_vec = vectorizer.transform(x_test)\n",
    "\n",
    "document_term_matrix = vectorizer.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "692c87e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "# classify using support vector classifier\n",
    "svm = svm.SVC(kernel = 'linear', probability=True)\n",
    "\n",
    "# fit the SVC model based on the given training data\n",
    "prob = svm.fit(x_train_vec, y_train).predict_proba(x_test_vec)\n",
    "\n",
    "# perform classification and prediction on samples in x_test\n",
    "y_pred_svm = svm.predict(x_test_vec)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2fb0dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for SVC is:  81.3758389261745 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy score for SVC is: \", accuracy_score(y_test, y_pred_svm) * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d47a532",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
